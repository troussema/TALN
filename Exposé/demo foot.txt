#-------------------------------------------------------------------------------------
# comparaison Real Madrid vs Liverpool Final UFEA CL savoir qui a + de positive tweets
#-------------------------------------------------------------------------------------

library(twitteR)
library(purrr)
library(dplyr)
library(ROAuth)
library(RCurl)
library(plyr)
library(stringr)
library(httpuv)
library(RJSONIO)
library(base64enc)

#CLEAN FONCTION
clean.text <- function(some_txt)
{
some_txt = gsub("(RT|via)((?:\\b\\W*@\\w+)+)", "", some_txt)
some_txt = gsub("@\\w+", "", some_txt)
some_txt = gsub("[[:punct:]]", "", some_txt)
some_txt = gsub("[[:digit:]]", "", some_txt)
some_txt = gsub("http\\w+", "", some_txt)
some_txt = gsub("[ t]{2,}", "", some_txt)
some_txt = gsub("^\\s+|\\s+$", "", some_txt)
some_txt= gsub("[^[:alpha:][:space:]]*" , "",some_txt)
some_txt = gsub("[\r\n]", "", some_txt)


# define "tolower error handling" function
try.tolower = function(x)
{
y = NA
try_error = tryCatch(tolower(x), error=function(e) e)
if (!inherits(try_error, "error"))
y = tolower(x)
return(y)
}
 
some_txt = sapply(some_txt, try.tolower)
some_txt = some_txt[some_txt != ""]
names(some_txt) = NULL
return(some_txt)
}


#SENTIMENT FONCTION 


score.sentiment = function(sentences, pos.words, neg.words, .progress='none')
  {
    require(plyr);
    require(stringr);
    scores = laply(sentences, function(sentence, pos.words, neg.words) {
      
      word.list = str_split(sentence, '\\s+');
      words = unlist(word.list);
      pos.matches = match(words, pos.words);
      neg.matches = match(words, neg.words);
      pos.matches = !is.na(pos.matches);
      neg.matches = !is.na(neg.matches);
      score = sum(pos.matches) - sum(neg.matches);
      return(score);
    }, pos.words, neg.words, .progress=.progress );
    scores.df = data.frame(score=scores, text=sentences);
    return(scores.df);
  }


#inclusion fichier source positive et negative

pos.words=readLines('positive-words.txt')
neg.words=readLines('negative-words.txt')


#--------------------- Connexion a Twitter ----
options(httr_oauth_cache=T)
api_key <- "ysfOY1g0bmwHjmXOZntO2cvwX" # your api_key
api_secret <- "F7Ua47b0PEqMjw2vVgsIxcvCfEBpS28QNlg8j13PXmWSl8sZe5" # your api_secret
access_token <- "139211163-epsqiu0LaZ0JlouxzF6jOF3X4kP55lybfjG54Nb1" # your access_token
access_token_secret <- "wHD5DgBJq66HUVCj2gwZoaRmwSGquub70EwpJulFmAXT8" # your access_token_secret

setup_twitter_oauth(api_key,api_secret,access_token,access_token_secret)
#----------------------------------------------

tweet1 <-searchTwitter('real madrid',n=250,lang="en",resultType="recent")
tweet2 <- searchTwitter('liverpool',n=250,lang="en",resultType="recent")


tweet_txt <- sapply(tweet1,function(x) x$getText())
tweet2_txt <- sapply(tweet2,function(x) x$getText())

tweet_clean = clean.text(tweet_txt)
tweet2_clean = clean.text(tweet2_txt)
	

#----------------appel fonction----

rscore <- score.sentiment(tweet_clean,pos.words,neg.words,.progress='text')
ascore <- score.sentiment(tweet2_clean,pos.words,neg.words,.progress='text')


#test
#sample=c("You're awesome and I love you",
#I hate and hate and hate. So angry. Die!",
#"Impressed and amazed: you are peerless in your achievement of unparalleled mediocrity.")
 #result=score.sentiment(sample,pos.words,neg.words,.progress='text')

#-------------------Histogram----- 
hist(rscore$score)
hist(ascore$score)
#------------------------------

net=count(rscore$score[rscore$score==0])
pos=count(rscore$score[rscore$score>0])
neg=count(rscore$score[rscore$score<0])


#-------autre methode --------------------
getSentiment <- function (text, key){
 
text <- URLencode(text);
 
#save all the spaces, then get rid of the weird characters that break the API, then convert back the URL-encoded spaces.
text <- str_replace_all(text, "%20", " ");
text <- str_replace_all(text, "%\\d\\d", "");
text <- str_replace_all(text, " ", "%20");
 
if (str_length(text) > 360){
text <- substr(text, 0, 359);
}
##########################################
 
data <- getURL(paste("http://api.datumbox.com/1.0/TwitterSentimentAnalysis.json?api_key=", key, "&text=",text, sep=""))
 
js <- fromJSON(data, asText=TRUE);
 
# get mood probability
sentiment = js$output$result
 
###################################
 
data <- getURL(paste("http://api.datumbox.com/1.0/SubjectivityAnalysis.json?api_key=", key, "&text=",text, sep=""))
 
js <- fromJSON(data, asText=TRUE);
 
# get mood probability
subject = js$output$result
 
##################################
 
data <- getURL(paste("http://api.datumbox.com/1.0/TopicClassification.json?api_key=", key, "&text=",text, sep=""))
 
js <- fromJSON(data, asText=TRUE);
 
# get mood probability
topic = js$output$result
 
##################################
data <- getURL(paste("http://api.datumbox.com/1.0/GenderDetection.json?api_key=", key, "&text=",text, sep=""))
 
js <- fromJSON(data, asText=TRUE);
 
# get mood probability
gender = js$output$result
 
return(list(sentiment=sentiment,subject=subject,topic=topic,gender=gender))
}

#-----------------------------------------
tweet_num = length(tweet_clean)

tweet_df = data.frame(text=tweet_clean, sentiment=rep("", tweet_num),
subject=1:tweet_num, topic=1:tweet_num, gender=1:tweet_num, stringsAsFactors=FALSE)



#----------------------------------apply function getSentiment
sentiment = rep(0, tweet_num)
for (i in 1:tweet_num)
{
tmp = getSentiment(tweet_clean[i], "33c4311abfe781eccd66995aa9d37056")
 
tweet_df$sentiment[i] = tmp$sentiment
 
tweet_df$subject[i] = tmp$subject
tweet_df$topic[i] = tmp$topic
tweet_df$gender[i] = tmp$gender
}
#------affichage et enregistrement
tweet_dft
write.table(tweet_df,file=Analysis.csv,sep=",",row.names=F)